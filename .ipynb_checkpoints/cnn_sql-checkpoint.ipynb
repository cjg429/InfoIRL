{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_coverage\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from CNNSQLAgent import CNNSQLAgent\n",
    "from collections import deque\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Coverage-v1')\n",
    "env.seed(seed)\n",
    "N_F_pos = env.observation_space.spaces[0].n\n",
    "N_F_map = env.observation_space.spaces[1].shape[0]\n",
    "N_F = N_F_pos + N_F_map\n",
    "N_A = env.action_space.n\n",
    "agent = CNNDQNAgent(N_F_pos, N_F_map, N_A, epsilon_decay= 0.99999, memory_mode='NORMAL', target_mode='DQN', batch_size=64)\n",
    "#agent.restore_model(path=\"model/coverage_8_cnn_dqn_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss : nan, return : -281.000, eps : 1.000\n",
      "1000 loss : nan, return : -248.600, eps : 0.959\n",
      "2000 loss : 1315.159, return : -276.100, eps : 0.918\n",
      "3000 loss : 484.504, return : -233.300, eps : 0.879\n",
      "4000 loss : 877.513, return : -219.000, eps : 0.841\n",
      "5000 loss : 870.419, return : -258.900, eps : 0.799\n",
      "6000 loss : 2588.451, return : -220.700, eps : 0.755\n",
      "7000 loss : 1130.875, return : -186.300, eps : 0.708\n",
      "8000 loss : 754.117, return : -242.400, eps : 0.662\n",
      "9000 loss : 653.454, return : -238.500, eps : 0.617\n",
      "10000 loss : 1324.703, return : -222.400, eps : 0.573\n",
      "11000 loss : 2077.332, return : -194.000, eps : 0.526\n",
      "12000 loss : 2812.351, return : -163.500, eps : 0.478\n",
      "13000 loss : 1320.456, return : -225.700, eps : 0.430\n",
      "14000 loss : 1636.634, return : -172.300, eps : 0.380\n",
      "15000 loss : 3023.790, return : -142.000, eps : 0.331\n",
      "16000 loss : 2080.624, return : -76.200, eps : 0.280\n",
      "17000 loss : 1919.652, return : -81.700, eps : 0.232\n",
      "18000 loss : 816.755, return : -127.300, eps : 0.188\n",
      "full cover\n",
      "19000 loss : 475.799, return : -32.700, eps : 0.146\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "20000 loss : 977.973, return : 50.300, eps : 0.108\n",
      "full cover\n",
      "full cover\n",
      "21000 loss : 1409.699, return : 45.300, eps : 0.076\n",
      "full cover\n",
      "22000 loss : 1445.939, return : 58.300, eps : 0.046\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "23000 loss : 752.796, return : 174.700, eps : 0.026\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "24000 loss : 1539.496, return : 297.700, eps : 0.013\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "25000 loss : 893.095, return : 384.100, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "26000 loss : 1764.536, return : 338.700, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "27000 loss : 711.802, return : 350.500, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "28000 loss : 1110.089, return : 274.800, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "29000 loss : 762.378, return : 293.200, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "30000 loss : 765.814, return : 325.300, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "31000 loss : 595.082, return : 369.000, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "32000 loss : 420.752, return : 342.100, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "33000 loss : 900.425, return : 161.700, eps : 0.010\n",
      "full cover\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bf0fb8837618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjg429/Desktop/coverage_RL/CNNDQNAgent.pyc\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mmap_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             loss, errors, _ = self.sess.run([self.loss, self.errors, self.optim], \n\u001b[0;32m--> 209\u001b[0;31m                                  feed_dict={self.pos_ph:pos_obs, self.map_ph:map_obs, self.target_ph:target, self.learning_rate_ph:self.learning_rate, self.batch_weights_ph:batch_weights})\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjg429/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjg429/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjg429/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjg429/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cjg429/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "max_t = 80\n",
    "avg_return_list = deque(maxlen=10)\n",
    "avg_loss_list = deque(maxlen=10)\n",
    "for i in range(500000):\n",
    "    obs = env.reset()\n",
    "    obs = np.concatenate((np.eye(64)[obs[0]], obs[1].flatten()))\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    #env.render()\n",
    "    #time.sleep(0.5)\n",
    "    for t in range(max_t):\n",
    "        action = agent.get_action(np.reshape(obs, (1, -1)))\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        next_obs = np.concatenate((np.eye(64)[next_obs[0]], next_obs[1].flatten()))\n",
    "        agent.add_experience(obs, action, reward, next_obs, done)\n",
    "        \n",
    "        loss = agent.train_model()\n",
    "        agent.update_memory(t, max_t)\n",
    "        agent.update_policy()\n",
    "        #env.render()\n",
    "        #time.sleep(0.5)\n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        total_loss += loss\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    agent.update_target()\n",
    "    avg_return_list.append(total_reward)\n",
    "    avg_loss_list.append(total_loss)\n",
    "    \n",
    "    if (i%1000)==0:\n",
    "        print('{} loss : {:.3f}, return : {:.3f}, eps : {:.3f}'.format(i, np.mean(avg_loss_list), np.mean(avg_return_list), agent.epsilon))\n",
    "#agent.save_model(path=\"model/coverage_6_model_new.ckpt\")\n",
    "#agent.restore_model(path=\"model/coverage_6_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n",
      "265\n",
      "202\n",
      "307\n",
      "34\n",
      "76\n",
      "34\n",
      "34\n",
      "55\n",
      "370\n",
      "412\n",
      "13\n",
      "244\n",
      "55\n",
      "76\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "agent.save_model(path=\"model/coverage_8_cnn_dqn_model.ckpt\")\n",
    "max_t = 50\n",
    "for i in range(100):\n",
    "    obs = env.reset()\n",
    "    obs = np.concatenate((np.eye(64)[obs[0]], obs[1].flatten()))\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    env.render()\n",
    "    time.sleep(0.25)\n",
    "    for t in range(max_t):\n",
    "        action = agent.get_action(np.reshape(obs, (1, -1)))\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        next_obs = np.concatenate((np.eye(64)[next_obs[0]], next_obs[1].flatten()))\n",
    "        \n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "        time.sleep(0.25)\n",
    "        if done:\n",
    "            break\n",
    "    print(total_reward)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
