{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_coverage\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from CNNDQNAgent import CNNDQNAgent\n",
    "from collections import deque\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Coverage-v1')\n",
    "env.seed(seed)\n",
    "N_F_pos = env.observation_space.spaces[0].n\n",
    "N_F_map = env.observation_space.spaces[1].shape[0]\n",
    "N_F = N_F_pos + N_F_map\n",
    "N_A = env.action_space.n\n",
    "agent = CNNDQNAgent(N_F_pos, N_F_map, N_A, epsilon_decay= 0.99999, memory_mode='NORMAL', target_mode='DQN', batch_size=64)\n",
    "#agent.restore_model(path=\"model/coverage_8_cnn_dqn_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss : 656.619, return : 466.000, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "1000 loss : 652.664, return : 262.200, eps : 0.010\n",
      "full cover\n",
      "2000 loss : 553.972, return : 350.100, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "3000 loss : 563.927, return : 158.200, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "4000 loss : 474.605, return : 157.400, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "5000 loss : 787.976, return : 204.100, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "6000 loss : 532.435, return : 157.500, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "7000 loss : 669.969, return : 282.500, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "8000 loss : 523.640, return : 385.700, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "9000 loss : 586.709, return : 352.200, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "10000 loss : 507.868, return : 156.200, eps : 0.010\n",
      "full cover\n",
      "11000 loss : 545.770, return : 341.000, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "12000 loss : 1615.206, return : 302.100, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "13000 loss : 632.883, return : 212.400, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "14000 loss : 586.570, return : 330.800, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "15000 loss : 699.351, return : 316.900, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "16000 loss : 930.923, return : 202.400, eps : 0.010\n",
      "full cover\n",
      "17000 loss : 855.754, return : 291.400, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "18000 loss : 667.413, return : 530.200, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "19000 loss : 770.307, return : 106.100, eps : 0.010\n",
      "20000 loss : 623.375, return : 50.800, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "21000 loss : 614.807, return : 302.300, eps : 0.010\n",
      "full cover\n",
      "full cover\n",
      "full cover\n",
      "22000 loss : 620.163, return : 109.300, eps : 0.010\n",
      "full cover\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "max_t = 80\n",
    "avg_return_list = deque(maxlen=10)\n",
    "avg_loss_list = deque(maxlen=10)\n",
    "for i in range(500000):\n",
    "    obs = env.reset()\n",
    "    obs = np.concatenate((np.eye(64)[obs[0]], obs[1].flatten()))\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    #env.render()\n",
    "    #time.sleep(0.5)\n",
    "    for t in range(max_t):\n",
    "        action = agent.get_action(np.reshape(obs, (1, -1)))\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        next_obs = np.concatenate((np.eye(64)[next_obs[0]], next_obs[1].flatten()))\n",
    "        agent.add_experience(obs, action, reward, next_obs, done)\n",
    "        \n",
    "        loss = agent.train_model()\n",
    "        agent.update_memory(t, max_t)\n",
    "        agent.update_policy()\n",
    "        #env.render()\n",
    "        #time.sleep(0.5)\n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        total_loss += loss\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    agent.update_target()\n",
    "    avg_return_list.append(total_reward)\n",
    "    avg_loss_list.append(total_loss)\n",
    "    \n",
    "    if (i%1000)==0:\n",
    "        print('{} loss : {:.3f}, return : {:.3f}, eps : {:.3f}'.format(i, np.mean(avg_loss_list), np.mean(avg_return_list), agent.epsilon))\n",
    "#agent.save_model(path=\"model/coverage_6_model_new.ckpt\")\n",
    "#agent.restore_model(path=\"model/coverage_6_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n",
      "265\n",
      "202\n",
      "307\n",
      "34\n",
      "76\n",
      "34\n",
      "34\n",
      "55\n",
      "370\n",
      "412\n",
      "13\n",
      "244\n",
      "55\n",
      "76\n",
      "34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e5c5d9f165f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.save_model(path=\"model/coverage_8_cnn_dqn_model.ckpt\")\n",
    "max_t = 50\n",
    "for i in range(100):\n",
    "    obs = env.reset()\n",
    "    obs = np.concatenate((np.eye(64)[obs[0]], obs[1].flatten()))\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    env.render()\n",
    "    time.sleep(0.25)\n",
    "    for t in range(max_t):\n",
    "        action = agent.get_action(np.reshape(obs, (1, -1)))\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        next_obs = np.concatenate((np.eye(64)[next_obs[0]], next_obs[1].flatten()))\n",
    "        \n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "        time.sleep(0.25)\n",
    "        if done:\n",
    "            break\n",
    "    print(total_reward)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
